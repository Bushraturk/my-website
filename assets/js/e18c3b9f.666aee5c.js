"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[4732],{5916:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"gazebo-unity/lab-exercises/lab2","title":"Lab Exercise 2 - Unity Perception Pipeline Integration","description":"Objective","source":"@site/docs/gazebo-unity/lab-exercises/lab2.md","sourceDirName":"gazebo-unity/lab-exercises","slug":"/gazebo-unity/lab-exercises/lab2","permalink":"/my-website/gazebo-unity/lab-exercises/lab2","draft":false,"unlisted":false,"editUrl":"https://github.com/Bushraturk/my-website/edit/main/docs/docs/gazebo-unity/lab-exercises/lab2.md","tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"title":"Lab Exercise 2 - Unity Perception Pipeline Integration","sidebar_position":9},"sidebar":"textbookSidebar","previous":{"title":"Lab Exercise 1 - Gazebo Simulation Environment Setup","permalink":"/my-website/gazebo-unity/lab-exercises/lab1"},"next":{"title":"Quiz 1 - Gazebo/Unity Simulation Concepts","permalink":"/my-website/gazebo-unity/assessments/quiz1"}}');var t=i(4848),a=i(8453);const s={title:"Lab Exercise 2 - Unity Perception Pipeline Integration",sidebar_position:9},l="Lab Exercise 2: Unity Perception Pipeline Integration",o={},c=[{value:"Objective",id:"objective",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Equipment Required",id:"equipment-required",level:2},{value:"Lab Steps",id:"lab-steps",level:2},{value:"Step 1: Setting Up Unity Environment",id:"step-1-setting-up-unity-environment",level:3},{value:"Step 2: Creating a Realistic Environment",id:"step-2-creating-a-realistic-environment",level:3},{value:"Step 3: Setting Up Sensor Simulation",id:"step-3-setting-up-sensor-simulation",level:3},{value:"Step 4: Adding Objects for Detection",id:"step-4-adding-objects-for-detection",level:3},{value:"Step 5: Configuring Synthetic Data Generation",id:"step-5-configuring-synthetic-data-generation",level:3},{value:"Step 6: Running the Simulation and Collecting Data",id:"step-6-running-the-simulation-and-collecting-data",level:3},{value:"Step 7: Analyzing Captured Data",id:"step-7-analyzing-captured-data",level:3},{value:"Expected Results",id:"expected-results",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Extension Activities",id:"extension-activities",level:2},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"lab-exercise-2-unity-perception-pipeline-integration",children:"Lab Exercise 2: Unity Perception Pipeline Integration"})}),"\n",(0,t.jsx)(n.h2,{id:"objective",children:"Objective"}),"\n",(0,t.jsx)(n.p,{children:"In this lab exercise, you will implement a perception pipeline using Unity's high-fidelity rendering to generate synthetic data for training an object detection model. You'll learn to create realistic environments, configure sensor models, and validate perception systems before real-world deployment."}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"After completing this lab, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Configure Unity for synthetic data generation"}),"\n",(0,t.jsx)(n.li,{children:"Set up realistic camera sensors with appropriate parameters"}),"\n",(0,t.jsx)(n.li,{children:"Create labeled datasets for object detection training"}),"\n",(0,t.jsx)(n.li,{children:"Compare perception results between Unity simulation and real-world data"}),"\n",(0,t.jsx)(n.li,{children:"Validate perception algorithms in a photo-realistic environment"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Completion of Gazebo/Unity Week 6 content"}),"\n",(0,t.jsx)(n.li,{children:"Unity installation with Robotics packages"}),"\n",(0,t.jsx)(n.li,{children:"Basic knowledge of computer vision concepts"}),"\n",(0,t.jsx)(n.li,{children:"Understanding of object detection algorithms"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"equipment-required",children:"Equipment Required"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Computer with Unity Hub and Unity installed (2021.3 LTS or newer)"}),"\n",(0,t.jsx)(n.li,{children:"Unity Robotics Hub and Perception package installed"}),"\n",(0,t.jsx)(n.li,{children:"Python environment with OpenCV and related libraries"}),"\n",(0,t.jsx)(n.li,{children:"At least 8GB RAM recommended"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lab-steps",children:"Lab Steps"}),"\n",(0,t.jsx)(n.h3,{id:"step-1-setting-up-unity-environment",children:"Step 1: Setting Up Unity Environment"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create a new Unity project for robotics simulation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Open Unity Hub"}),"\n",(0,t.jsx)(n.li,{children:'Click "New Project"'}),"\n",(0,t.jsx)(n.li,{children:'Select "3D (Built-in Render Pipeline)" template'}),"\n",(0,t.jsx)(n.li,{children:'Name the project "UnityPerceptionTutorial"'}),"\n",(0,t.jsx)(n.li,{children:"Make sure the render pipeline is compatible with Perception package"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install required packages:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Open the Package Manager (Window > Package Manager)"}),"\n",(0,t.jsx)(n.li,{children:'Install "Unity Perception" package'}),"\n",(0,t.jsx)(n.li,{children:'Install "Robotics" package'}),"\n",(0,t.jsx)(n.li,{children:'Install "ROS# (Robot Operating System)" if you plan to interface with ROS'}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Set up the scene with realistic lighting:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Add a Directional Light for sun simulation"}),"\n",(0,t.jsx)(n.li,{children:"Configure Environment Lighting with realistic settings"}),"\n",(0,t.jsx)(n.li,{children:"Add Reflection Probes for accurate reflections"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-2-creating-a-realistic-environment",children:"Step 2: Creating a Realistic Environment"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Design a warehouse-like environment:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Create floor using a large plane (10x10 units)"}),"\n",(0,t.jsx)(n.li,{children:"Add warehouse shelving units using basic primitives"}),"\n",(0,t.jsx)(n.li,{children:"Create objects to detect (cubes, spheres, cylinders)"}),"\n",(0,t.jsx)(n.li,{children:"Add realistic materials to all objects"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Configure environmental parameters:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class EnvironmentManager : MonoBehaviour\r\n{\r\n    [Header("Lighting Settings")]\r\n    public Light sunLight;\r\n    public Color ambientColor = Color.gray;\r\n    [Range(0, 2)] public float intensity = 1.0f;\r\n    \r\n    [Header("Weather Settings")]\r\n    [Range(0, 0.1f)] public float fogDensity = 0.0f;\r\n    \r\n    void Start()\r\n    {\r\n        // Configure lighting\r\n        RenderSettings.ambientLight = ambientColor;\r\n        sunLight.intensity = intensity;\r\n        \r\n        // Configure fog based on weather\r\n        RenderSettings.fog = true;\r\n        RenderSettings.fogDensity = fogDensity;\r\n        RenderSettings.fogColor = Color.Lerp(Color.white, ambientColor, 0.5f);\r\n    }\r\n}\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-3-setting-up-sensor-simulation",children:"Step 3: Setting Up Sensor Simulation"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create a robot with a camera sensor:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Create an empty GameObject named "Robot"'}),"\n",(0,t.jsx)(n.li,{children:"Add a simple cube as the robot body"}),"\n",(0,t.jsx)(n.li,{children:"Position a camera at the front of the robot (e.g., at position [0.3, 0.5, 0])"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Configure the Perception Camera:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Attach the "Camera Sensor" component from the Perception package to the camera'}),"\n",(0,t.jsx)(n.li,{children:'Set the Camera ID to "perception_cam"'}),"\n",(0,t.jsxs)(n.li,{children:["Configure the following parameters:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Width: 640"}),"\n",(0,t.jsx)(n.li,{children:"Height: 480"}),"\n",(0,t.jsx)(n.li,{children:"Field of View: 60\xb0"}),"\n",(0,t.jsx)(n.li,{children:"Enable Semantic Segmentation"}),"\n",(0,t.jsx)(n.li,{children:"Enable Bounding Box generation"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Implement the camera setup script:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.Sensors;\r\nusing Unity.Robotics.Perception;\r\nusing Unity.Robotics.Perception.GroundTruth;\r\n\r\npublic class PerceptionCameraSetup : MonoBehaviour\r\n{\r\n    [SerializeField] private Sensor sensor;\r\n    [SerializeField] private Camera cam;\r\n    \r\n    [Header("Camera Properties")]\r\n    [Range(30f, 120f)] public float fieldOfView = 60f;\r\n    [Range(0.1f, 1000f)] public float nearClip = 0.1f;\r\n    [Range(1f, 1000f)] public float farClip = 100f;\r\n    \r\n    [Header("Perception Settings")]\r\n    public bool enableSegmentation = true;\r\n    public bool enableBbLabeler = true;\r\n    public bool enableOpticalFlow = false;\r\n    \r\n    void Start()\r\n    {\r\n        ConfigureCamera();\r\n        ConfigurePerceptionComponents();\r\n    }\r\n    \r\n    void ConfigureCamera()\r\n    {\r\n        cam.fieldOfView = fieldOfView;\r\n        cam.nearClipPlane = nearClip;\r\n        cam.farClipPlane = farClip;\r\n    }\r\n    \r\n    void ConfigurePerceptionComponents()\r\n    {\r\n        if (enableSegmentation)\r\n        {\r\n            var segLabeler = sensor.GetComponent<SegmentationLabeler>();\r\n            if (segLabeler == null)\r\n                segLabeler = sensor.gameObject.AddComponent<SegmentationLabeler>();\r\n        }\r\n        \r\n        if (enableBbLabeler)\r\n        {\r\n            var bbLabeler = sensor.GetComponent<BoundingBoxLabeler>();\r\n            if (bbLabeler == null)\r\n                bbLabeler = sensor.gameObject.AddComponent<BoundingBoxLabeler>();\r\n        }\r\n        \r\n        if (enableOpticalFlow)\r\n        {\r\n            var optFlowLabeler = sensor.GetComponent<OpticalFlowLabeler>();\r\n            if (optFlowLabeler == null)\r\n                optFlowLabeler = sensor.gameObject.AddComponent<OpticalFlowLabeler>();\r\n        }\r\n    }\r\n}\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-4-adding-objects-for-detection",children:"Step 4: Adding Objects for Detection"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create object prefabs with semantic labels:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'Create a cube prefab named "Box"'}),"\n",(0,t.jsx)(n.li,{children:'Create a sphere prefab named "Ball"'}),"\n",(0,t.jsx)(n.li,{children:'Create a cylinder prefab named "Can"'}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Assign semantic labels to objects:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using Unity.Robotics.Perception;\r\nusing UnityEngine;\r\n\r\npublic class ObjectSemanticLabel : MonoBehaviour, ISegmentable\r\n{\r\n    [SerializeField] private string semanticLabel = "object";\r\n    [SerializeField] private int semanticId = -1;\r\n    \r\n    public string GetSemanticLabel()\r\n    {\r\n        return semanticLabel;\r\n    }\r\n    \r\n    public int GetSemanticId()\r\n    {\r\n        if (semanticId == -1)\r\n        {\r\n            // Auto assign ID if not set\r\n            semanticId = SegmentationTagManager.Instance.GetNextAvailableId();\r\n        }\r\n        return semanticId;\r\n    }\r\n}\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Place objects randomly in the environment:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\n\r\npublic class RandomObjectSpawner : MonoBehaviour\r\n{\r\n    [Header("Object Prefabs")]\r\n    public GameObject[] objectPrefabs;\r\n    \r\n    [Header("Environment Settings")]\r\n    public Vector2 spawnArea = new Vector2(8, 8);  // Range for x and z coordinates\r\n    [Range(0, 5)] public float minHeight = 0.3f;\r\n    [Range(0, 5)] public float maxHeight = 2f;\r\n    \r\n    [Header("Spawn Settings")]\r\n    [Range(1, 50)] public int maxObjects = 10;\r\n    \r\n    private List<GameObject> spawnedObjects = new List<GameObject>();\r\n    \r\n    void Start()\r\n    {\r\n        SpawnObjects();\r\n    }\r\n    \r\n    public void SpawnObjects()\r\n    {\r\n        // Clear previous objects\r\n        foreach (var obj in spawnedObjects)\r\n        {\r\n            if (obj != null) DestroyImmediate(obj);\r\n        }\r\n        spawnedObjects.Clear();\r\n        \r\n        int numToSpawn = Random.Range(3, maxObjects + 1);\r\n        \r\n        for (int i = 0; i < numToSpawn; i++)\r\n        {\r\n            SpawnSingleObject();\r\n        }\r\n    }\r\n    \r\n    void SpawnSingleObject()\r\n    {\r\n        if (objectPrefabs.Length == 0) return;\r\n        \r\n        // Select random prefab\r\n        GameObject prefab = objectPrefabs[Random.Range(0, objectPrefabs.Length)];\r\n        \r\n        // Generate random position\r\n        Vector3 pos = new Vector3(\r\n            Random.Range(-spawnArea.x/2, spawnArea.x/2),\r\n            Random.Range(minHeight, maxHeight),\r\n            Random.Range(-spawnArea.y/2, spawnArea.y/2)\r\n        );\r\n        \r\n        // Create object and store reference\r\n        GameObject instance = Instantiate(prefab, pos, Quaternion.identity);\r\n        instance.transform.SetParent(transform);\r\n        spawnedObjects.Add(instance);\r\n    }\r\n}\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-5-configuring-synthetic-data-generation",children:"Step 5: Configuring Synthetic Data Generation"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Set up the Perception Camera Controller:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using Unity.Robotics.Perception;\r\nusing UnityEngine;\r\nusing System.Collections.Generic;\r\n\r\npublic class PerceptionController : MonoBehaviour\r\n{\r\n    [Header("Capture Settings")]\r\n    [Range(0.1f, 2f)] public float captureInterval = 1f;\r\n    public string outputDirectory = "PerceptionOutput";\r\n    public int numFramesToCapture = 100;\r\n    \r\n    [Header("Annotation Settings")]\r\n    public bool captureRGB = true;\r\n    public bool captureDepth = false;\r\n    public bool captureSegmentation = true;\r\n    public bool captureBoundingBoxes = true;\r\n    \r\n    private int frameCount = 0;\r\n    private float lastCaptureTime;\r\n    \r\n    void Start()\r\n    {\r\n        lastCaptureTime = Time.time;\r\n        \r\n        // Configure perception manager\r\n        PerceptionManager.Instance.outputDirectory = outputDirectory;\r\n        PerceptionManager.Instance.maxNumSamples = numFramesToCapture;\r\n    }\r\n    \r\n    void Update()\r\n    {\r\n        if (frameCount >= numFramesToCapture) return;\r\n        \r\n        if (Time.time - lastCaptureTime >= captureInterval)\r\n        {\r\n            CaptureFrame();\r\n            lastCaptureTime = Time.time;\r\n            frameCount++;\r\n        }\r\n    }\r\n    \r\n    void CaptureFrame()\r\n    {\r\n        // Generate random environmental variations for more diverse data\r\n        GenerateEnvironmentalVariations();\r\n        \r\n        // Trigger perception capture\r\n        PerceptionManager.Instance.CaptureSample();\r\n        \r\n        Debug.Log($"Captured frame {frameCount}/{numFramesToCapture}");\r\n    }\r\n    \r\n    void GenerateEnvironmentalVariations()\r\n    {\r\n        // Change lighting conditions\r\n        var lights = FindObjectsByType<Light>(FindObjectsSortMode.None);\r\n        foreach (var light in lights)\r\n        {\r\n            // Add slight variations to lighting\r\n            light.intensity = Random.Range(0.8f, 1.2f);\r\n        }\r\n        \r\n        // Change material colors slightly\r\n        var renderers = FindObjectsByType<Renderer>(FindObjectsSortMode.None);\r\n        foreach (var renderer in renderers)\r\n        {\r\n            if (renderer.material.HasProperty("_Color"))\r\n            {\r\n                var baseColor = renderer.material.color;\r\n                var variation = new Color(\r\n                    Mathf.Clamp01(baseColor.r + Random.Range(-0.1f, 0.1f)),\r\n                    Mathf.Clamp01(baseColor.g + Random.Range(-0.1f, 0.1f)),\r\n                    Mathf.Clamp01(baseColor.b + Random.Range(-0.1f, 0.1f)),\r\n                    baseColor.a\r\n                );\r\n                renderer.material.color = variation;\r\n            }\r\n        }\r\n    }\r\n}\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-6-running-the-simulation-and-collecting-data",children:"Step 6: Running the Simulation and Collecting Data"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Set up the Unity scene:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Add the PerceptionCameraSetup script to your camera"}),"\n",(0,t.jsx)(n.li,{children:"Add the RandomObjectSpawner to a GameObject in your scene"}),"\n",(0,t.jsx)(n.li,{children:"Add the PerceptionController to manage data collection"}),"\n",(0,t.jsx)(n.li,{children:"Create prefabs for the objects to detect with semantic labels"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Configure the Perception Manager:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"In the Unity menu, go to Window > Perception > Perception Manager"}),"\n",(0,t.jsx)(n.li,{children:"Set up the required settings for data capture"}),"\n",(0,t.jsx)(n.li,{children:"Configure annotation types you want to capture"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Run the simulation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Press Play in Unity"}),"\n",(0,t.jsx)(n.li,{children:"The simulation will automatically capture frames with annotations"}),"\n",(0,t.jsx)(n.li,{children:"Data will be saved to the specified output directory"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"step-7-analyzing-captured-data",children:"Step 7: Analyzing Captured Data"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The captured data will include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"RGB images"}),"\n",(0,t.jsx)(n.li,{children:"Semantic segmentation masks"}),"\n",(0,t.jsx)(n.li,{children:"Bounding box annotations"}),"\n",(0,t.jsx)(n.li,{children:"Metadata files with camera parameters"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"You can load and visualize the data using Python:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import cv2\r\nimport numpy as np\r\nimport json\r\nimport os\r\n\r\ndef visualize_annotations(rgb_path, seg_path, bboxes_path):\r\n    # Load RGB image\r\n    rgb_img = cv2.imread(rgb_path)\r\n    \r\n    # Load segmentation mask\r\n    seg_img = cv2.imread(seg_path, cv2.IMREAD_UNCHANGED)\r\n    \r\n    # Load bounding box annotations\r\n    with open(bboxes_path, 'r') as f:\r\n        bboxes_data = json.load(f)\r\n    \r\n    # Draw bounding boxes on the RGB image\r\n    for bbox in bboxes_data['captures'][0]['annotations']:\r\n        if bbox['id'] == '2d_bounding_box':\r\n            for box in bbox['data']:\r\n                # Extract bounding box coordinates\r\n                x_min = int(box['x'])\r\n                y_min = int(box['y'])\r\n                x_max = x_min + int(box['width'])\r\n                y_max = y_min + int(box['height'])\r\n                \r\n                # Draw bounding box\r\n                cv2.rectangle(rgb_img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\r\n                cv2.putText(rgb_img, box['label'], (x_min, y_min - 10), \r\n                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\r\n    \r\n    # Show the annotated image\r\n    cv2.imshow('Annotated Image', rgb_img)\r\n    cv2.waitKey(0)\r\n    cv2.destroyAllWindows()\r\n\r\n# Example usage\r\nvisualize_annotations(\r\n    'PerceptionOutput/frame_000000.color.png',\r\n    'PerceptionOutput/frame_000000.segmentation.png',\r\n    'PerceptionOutput/frame_000000.json'\r\n)\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"expected-results",children:"Expected Results"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The Unity simulation should generate diverse, photo-realistic images"}),"\n",(0,t.jsx)(n.li,{children:"Each image should have corresponding annotations (segmentation, bounding boxes)"}),"\n",(0,t.jsx)(n.li,{children:"The robot should navigate through various environmental conditions"}),"\n",(0,t.jsx)(n.li,{children:"The captured data should be suitable for training computer vision models"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If semantic segmentation isn't working, ensure all objects have the ISegmentable interface"}),"\n",(0,t.jsx)(n.li,{children:"If bounding boxes aren't generated, verify that objects have colliders and are properly labeled"}),"\n",(0,t.jsx)(n.li,{children:"If capture rate is too high, increase the captureInterval parameter"}),"\n",(0,t.jsx)(n.li,{children:"If Unity crashes during capture, reduce the capture rate or scene complexity"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"extension-activities",children:"Extension Activities"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Implement a dynamic scene where objects move during simulation"}),"\n",(0,t.jsx)(n.li,{children:"Add weather effects (rain, fog, etc.) to generate more diverse data"}),"\n",(0,t.jsx)(n.li,{children:"Train an object detection model using the generated synthetic data"}),"\n",(0,t.jsx)(n.li,{children:"Compare model performance on synthetic vs. real-world data"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"What are the advantages of synthetic data generation over real-world data collection for perception tasks?"}),"\n",(0,t.jsx)(n.li,{children:"How do variations in lighting and environment affect the performance of perception systems?"}),"\n",(0,t.jsx)(n.li,{children:"What limitations of Unity simulation for perception tasks did you identify?"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"This lab introduced you to Unity's perception capabilities for generating realistic training data for computer vision applications. You've created a complete pipeline for synthetic data generation with accurate annotations that can be used to train perception models for robotics applications."})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>l});var r=i(6540);const t={},a=r.createContext(t);function s(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);