"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[8363],{354:(e,n,i)=>{i.d(n,{A:()=>r});const r="data:image/png;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iNDAwIj48cmVjdCB3aWR0aD0iODAwIiBoZWlnaHQ9IjQwMCIgZmlsbD0iI2YwZjBmMCIvPjx0ZXh0IHg9IjQwMCIgeT0iMjAwIiBmb250LWZhbWlseT0iQXJpYWwiIGZvbnQtc2l6ZT0iMjAiIHRleHQtYW5jaG9yPSJtaWRkbGUiIGZpbGw9IiMzMzMiPkRpYWdyYW06IFVuaXR5IFBlcmNlcHRpb24gUGlwZWxpbmU8L3RleHQ+PC9zdmc+"},6211:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"gazebo-unity/week6","title":"Week 6 - Unity Integration and Advanced Sensors","description":"In this week, we\'ll explore Unity as a simulation platform for robotics and learn about advanced sensor simulation techniques. Unity provides high-fidelity rendering and a rich ecosystem of tools that complement the physics-accurate simulation offered by Gazebo.","source":"@site/docs/gazebo-unity/week6.md","sourceDirName":"gazebo-unity","slug":"/gazebo-unity/week6","permalink":"/gazebo-unity/week6","draft":false,"unlisted":false,"editUrl":"https://github.com/Bushraturk/Physical-AI-Book/edit/main/docs/gazebo-unity/week6.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Week 6 - Unity Integration and Advanced Sensors","sidebar_position":7},"sidebar":"textbookSidebar","previous":{"title":"Week 4-5 - Simulation Environments and Gazebo Integration","permalink":"/gazebo-unity/week4-5"},"next":{"title":"Lab Exercise 1 - Gazebo Simulation Environment Setup","permalink":"/gazebo-unity/lab-exercises/lab1"}}');var t=i(4848),o=i(8453);const a={title:"Week 6 - Unity Integration and Advanced Sensors",sidebar_position:7},s="Week 6: Unity Integration and Advanced Sensors",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Unity for Robotics",id:"introduction-to-unity-for-robotics",level:2},{value:"Unity Robotics Tools",id:"unity-robotics-tools",level:3},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"Installing Unity Robotics Packages",id:"installing-unity-robotics-packages",level:3},{value:"Basic Unity ROS Integration",id:"basic-unity-ros-integration",level:3},{value:"Advanced Sensor Simulation in Unity",id:"advanced-sensor-simulation-in-unity",level:2},{value:"Camera Sensors",id:"camera-sensors",level:3},{value:"LiDAR Simulation",id:"lidar-simulation",level:3},{value:"Advanced Unity Perception Features",id:"advanced-unity-perception-features",level:3},{value:"Unity vs Gazebo Comparison",id:"unity-vs-gazebo-comparison",level:2},{value:"Creating Photo-Realistic Environments",id:"creating-photo-realistic-environments",level:2},{value:"Environment Design Principles",id:"environment-design-principles",level:3},{value:"Sample Environment Setup",id:"sample-environment-setup",level:3},{value:"Cross-Platform Validation",id:"cross-platform-validation",level:2},{value:"Practical Applications in Industry",id:"practical-applications-in-industry",level:2},{value:"Lab Exercise Preview",id:"lab-exercise-preview",level:2},{value:"Summary",id:"summary",level:2},{value:"Navigation",id:"navigation",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"week-6-unity-integration-and-advanced-sensors",children:"Week 6: Unity Integration and Advanced Sensors"})}),"\n",(0,t.jsx)(n.p,{children:"In this week, we'll explore Unity as a simulation platform for robotics and learn about advanced sensor simulation techniques. Unity provides high-fidelity rendering and a rich ecosystem of tools that complement the physics-accurate simulation offered by Gazebo."}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this week, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set up Unity for robotics simulation scenarios"}),"\n",(0,t.jsx)(n.li,{children:"Implement advanced sensor models for cameras and LiDAR"}),"\n",(0,t.jsx)(n.li,{children:"Compare Unity and Gazebo simulation outputs"}),"\n",(0,t.jsx)(n.li,{children:"Design photo-realistic environments for perception tasks"}),"\n",(0,t.jsx)(n.li,{children:"Validate robot perception systems using Unity simulation"}),"\n",(0,t.jsx)(n.li,{children:"Transfer simulation results between platforms"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"introduction-to-unity-for-robotics",children:"Introduction to Unity for Robotics"}),"\n",(0,t.jsx)(n.p,{children:"Unity is a powerful game engine that provides high-fidelity visuals and a rich development environment. While originally designed for game development, Unity has become a valuable tool for robotics simulation, particularly for perception tasks requiring photo-realistic rendering."}),"\n",(0,t.jsx)(n.h3,{id:"unity-robotics-tools",children:"Unity Robotics Tools"}),"\n",(0,t.jsx)(n.p,{children:"Unity provides several tools specifically for robotics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Unity Robotics Hub"}),": Centralized package management for robotics tools"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Unity Perception Package"}),": Tools for generating synthetic data for training AI models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS#"}),": C# bridge for ROS communication"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ML-Agents"}),": Framework for training intelligent agents using deep reinforcement learning"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Unity Perception Pipeline",src:i(354).A+"",width:"800",height:"400"})}),"\n",(0,t.jsx)(n.h3,{id:"installing-unity-robotics-packages",children:"Installing Unity Robotics Packages"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Install Unity Hub and a recent version of Unity (2021.3 LTS or newer)"}),"\n",(0,t.jsx)(n.li,{children:"Install the Unity Robotics Hub from the Unity Asset Store"}),"\n",(0,t.jsx)(n.li,{children:"Add the ROS# package for ROS communication"}),"\n",(0,t.jsx)(n.li,{children:"Include the Perception package for synthetic data generation"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"basic-unity-ros-integration",children:"Basic Unity ROS Integration"}),"\n",(0,t.jsx)(n.p,{children:"Here's a basic Unity script to interface with ROS:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using System.Collections;\r\nusing UnityEngine;\r\nusing RosSharp;\r\nusing RosSharp.Messages.Geometry;\r\n\r\npublic class RobotController : MonoBehaviour\r\n{\r\n    [SerializeField] private string topicName = "robot_velocity";\r\n    private RosSocket rosSocket;\r\n    private Subscriber<Velocity> velocitySubscriber;\r\n\r\n    void Start()\r\n    {\r\n        // Initialize connection to ROS\r\n        rosSocket = new RosSocket(new RosSharp.Communication.Uri("ws://127.0.0.1:9090"));\r\n        velocitySubscriber = rosSocket.Subscribe<Velocity>(topicName, VelocityReceived);\r\n    }\r\n\r\n    private void VelocityReceived(Velocity velocity)\r\n    {\r\n        // Apply received velocity to the robot\r\n        transform.Translate(new Vector3(velocity.linear.x, 0, velocity.linear.z) * Time.deltaTime);\r\n    }\r\n\r\n    void OnApplicationQuit()\r\n    {\r\n        rosSocket.Close();\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"advanced-sensor-simulation-in-unity",children:"Advanced Sensor Simulation in Unity"}),"\n",(0,t.jsx)(n.h3,{id:"camera-sensors",children:"Camera Sensors"}),"\n",(0,t.jsx)(n.p,{children:"The Unity Perception package provides realistic camera simulation with several parameters:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"using Unity.Robotics.Perception;\r\nusing Unity.Robotics.Perception.GroundTruth;\r\n\r\npublic class CameraSensorSetup : MonoBehaviour\r\n{\r\n    [SerializeField] private Sensor sensor;\r\n\r\n    void Start()\r\n    {\r\n        var cameraSensor = sensor.GetComponent<CameraSensor>();\r\n\r\n        // Configure camera properties\r\n        cameraSensor.Camera.fieldOfView = 60f;  // Field of view in degrees\r\n        cameraSensor.Camera.nearClipPlane = 0.1f;\r\n        cameraSensor.Camera.farClipPlane = 100f;\r\n\r\n        // Enable depth rendering for depth camera\r\n        cameraSensor.EnableSegmentation = true;\r\n        cameraSensor.EnableOpticalFlow = true;\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"lidar-simulation",children:"LiDAR Simulation"}),"\n",(0,t.jsx)(n.p,{children:"Unity provides plugins for simulating LiDAR sensors with realistic noise models:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"using Unity.Robotics.Perception.LiDAR;\r\n\r\npublic class LiDARSensorSetup : MonoBehaviour\r\n{\r\n    [SerializeField] private LiDARManager liDARManager;\r\n\r\n    void Start()\r\n    {\r\n        // Configure LiDAR properties\r\n        liDARManager.Range = 20.0f;  // Max detection range in meters\r\n        liDARManager.AngleResolution = 0.25f;  // Angular resolution in degrees\r\n        liDARManager.VerticalAngleResolution = 0.5f;\r\n        liDARManager.VerticalAngleRange = new Vector2(-15.0f, 15.0f);\r\n\r\n        // Add noise model\r\n        liDARManager.NoiseModel = new GaussianNoiseModel(0.01f, 0.001f);\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"advanced-unity-perception-features",children:"Advanced Unity Perception Features"}),"\n",(0,t.jsx)(n.p,{children:"Here's an example of how to generate synthetic training data for computer vision models:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using Unity.Robotics.Perception;\r\nusing Unity.Robotics.Perception.GroundTruth;\r\nusing UnityEngine;\r\n\r\npublic class SyntheticDataGenerator : MonoBehaviour\r\n{\r\n    [Header("Capture Settings")]\r\n    [Range(0.1f, 5f)] public float captureInterval = 1f;\r\n    public string outputDirectory = "SyntheticData";\r\n    public bool captureRGB = true;\r\n    public bool captureDepth = true;\r\n    public bool captureSegmentation = true;\r\n    public bool captureBoundingBoxes = true;\r\n\r\n    private float lastCaptureTime;\r\n\r\n    void Start()\r\n    {\r\n        lastCaptureTime = Time.time;\r\n\r\n        // Configure the Perception Manager\r\n        PerceptionManager.Instance.outputDirectory = outputDirectory;\r\n        PerceptionManager.Instance.annotationCaptureRgb = captureRGB;\r\n        PerceptionManager.Instance.annotationCaptureDepth = captureDepth;\r\n        PerceptionManager.Instance.annotationCaptureSegmentation = captureSegmentation;\r\n        PerceptionManager.Instance.annotationCaptureBoundingBox2D = captureBoundingBoxes;\r\n    }\r\n\r\n    void Update()\r\n    {\r\n        if (Time.time - lastCaptureTime >= captureInterval)\r\n        {\r\n            // Add environmental variations\r\n            AddEnvironmentalVariations();\r\n\r\n            // Capture a sample with annotations\r\n            PerceptionManager.Instance.CaptureSample();\r\n\r\n            lastCaptureTime = Time.time;\r\n        }\r\n    }\r\n\r\n    void AddEnvironmentalVariations()\r\n    {\r\n        // Randomize lighting\r\n        var lights = FindObjectsOfType<Light>();\r\n        foreach (var light in lights)\r\n        {\r\n            // Add random variations to light properties\r\n            light.intensity = Mathf.Clamp(light.intensity + Random.Range(-0.1f, 0.1f), 0.5f, 1.5f);\r\n        }\r\n\r\n        // Apply random material changes\r\n        var renderers = FindObjectsOfType<Renderer>();\r\n        foreach (var renderer in renderers)\r\n        {\r\n            if (renderer.material.HasProperty("_Color"))\r\n            {\r\n                var originalColor = renderer.material.color;\r\n                var variation = new Color(\r\n                    Mathf.Clamp01(originalColor.r + Random.Range(-0.05f, 0.05f)),\r\n                    Mathf.Clamp01(originalColor.g + Random.Range(-0.05f, 0.05f)),\r\n                    Mathf.Clamp01(originalColor.b + Random.Range(-0.05f, 0.05f)),\r\n                    originalColor.a\r\n                );\r\n                renderer.material.color = variation;\r\n            }\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"unity-vs-gazebo-comparison",children:"Unity vs Gazebo Comparison"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Feature"}),(0,t.jsx)(n.th,{children:"Gazebo"}),(0,t.jsx)(n.th,{children:"Unity"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Physics Accuracy"}),(0,t.jsx)(n.td,{children:"High"}),(0,t.jsx)(n.td,{children:"Medium-High"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Visual Fidelity"}),(0,t.jsx)(n.td,{children:"Medium"}),(0,t.jsx)(n.td,{children:"High"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Sensor Simulation"}),(0,t.jsx)(n.td,{children:"Excellent"}),(0,t.jsx)(n.td,{children:"Excellent"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Development Speed"}),(0,t.jsx)(n.td,{children:"Fast"}),(0,t.jsx)(n.td,{children:"Medium"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Rendering Quality"}),(0,t.jsx)(n.td,{children:"Basic"}),(0,t.jsx)(n.td,{children:"Photorealistic"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Ecosystem"}),(0,t.jsx)(n.td,{children:"Robotics-focused"}),(0,t.jsx)(n.td,{children:"General-purpose"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"creating-photo-realistic-environments",children:"Creating Photo-Realistic Environments"}),"\n",(0,t.jsx)(n.p,{children:"Unity excels in creating visually realistic environments for perception tasks:"}),"\n",(0,t.jsx)(n.h3,{id:"environment-design-principles",children:"Environment Design Principles"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scene Complexity"}),": Balance visual quality with simulation performance"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lighting"}),": Use realistic lighting to match target environments"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Materials"}),": Use physically-based materials for accurate rendering"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Assets"}),": Use high-quality models that match real-world objects"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Weather"}),": Include weather variations for comprehensive testing"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"sample-environment-setup",children:"Sample Environment Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class EnvironmentSetup : MonoBehaviour\r\n{\r\n    public Light sunLight;\r\n    public GameObject[] environmentObjects;\r\n    \r\n    [System.Serializable]\r\n    public class WeatherSettings\r\n    {\r\n        public float fogDensity = 0.0f;\r\n        public Color skyColor = Color.blue;\r\n        public float windSpeed = 0.0f;\r\n    }\r\n    \r\n    public WeatherSettings currentWeather;\r\n    \r\n    void Start()\r\n    {\r\n        // Configure environmental settings\r\n        RenderSettings.fog = true;\r\n        RenderSettings.fogDensity = currentWeather.fogDensity;\r\n        RenderSettings.ambientSkyColor = currentWeather.skyColor;\r\n        \r\n        // Add wind zones for outdoor simulation\r\n        foreach (var obj in environmentObjects)\r\n        {\r\n            if (obj.CompareTag("WindZone"))\r\n            {\r\n                var windZone = obj.GetComponent<WindZone>();\r\n                windZone.windMain = currentWeather.windSpeed;\r\n            }\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"cross-platform-validation",children:"Cross-Platform Validation"}),"\n",(0,t.jsx)(n.p,{children:"Validating simulation results across platforms ensures robustness:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Consistent Metrics"}),": Use the same evaluation metrics in both Gazebo and Unity"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Shared Scenarios"}),": Create similar test scenarios in both environments"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Parameter Mapping"}),": Ensure physical parameters are consistent"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data Comparison"}),": Analyze performance differences between platforms"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"practical-applications-in-industry",children:"Practical Applications in Industry"}),"\n",(0,t.jsx)(n.p,{children:"Unity simulation is used in:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Autonomous vehicle perception training"}),"\n",(0,t.jsx)(n.li,{children:"Industrial robot path planning"}),"\n",(0,t.jsx)(n.li,{children:"Augmented reality applications"}),"\n",(0,t.jsx)(n.li,{children:"Training AI models with synthetic data"}),"\n",(0,t.jsx)(n.li,{children:"Human-robot interaction studies"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lab-exercise-preview",children:"Lab Exercise Preview"}),"\n",(0,t.jsx)(n.p,{children:"In the next section, you'll find the detailed instructions for the advanced Gazebo/Unity lab, where you'll implement a complete perception pipeline using both simulation platforms."}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"In this week, you've learned:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"How to set up Unity for robotics simulation"}),"\n",(0,t.jsx)(n.li,{children:"How to implement advanced sensor models in Unity"}),"\n",(0,t.jsx)(n.li,{children:"How to design photo-realistic environments for perception tasks"}),"\n",(0,t.jsx)(n.li,{children:"How to compare simulation results across platforms"}),"\n",(0,t.jsx)(n.li,{children:"The applications of Unity in robotics"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"navigation",children:"Navigation"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"/gazebo-unity/week4-5",children:"\u2190 Previous: Week 4-5: Simulation Environments"})," | ",(0,t.jsx)(n.a,{href:"/gazebo-unity/conclusion",children:"Next: Gazebo/Unity Module Conclusion"})," | ",(0,t.jsx)(n.a,{href:"/gazebo-unity/intro",children:"Module Home"})]}),"\n",(0,t.jsxs)(n.p,{children:["Continue to ",(0,t.jsx)(n.a,{href:"/gazebo-unity/conclusion",children:"Gazebo/Unity Module Conclusion"})," to review what you've learned and how it connects to the next modules."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>s});var r=i(6540);const t={},o=r.createContext(t);function a(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);